\documentclass{beamer}
\usepackage[english]{babel}
\usetheme{CambridgeUS}

\usepackage{caption}
\captionsetup{tableposition=top,figureposition=bottom,font=small}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{grffile}
\usepackage{booktabs}
\usepackage[absolute,overlay]{textpos}
\usepackage[noend,noline,tworuled]{algorithm2e}
\usepackage{minted}
\usepackage{calc}
\setlength{\parskip}{\smallskipamount}

\setbeamertemplate{navigation symbols}{}

\title[]{Screen Space Ambient Occlusion \\\small A WebGL-three.js implementation}

\newsavebox{\authbox}
\sbox{\authbox}{
    \centering
    \begin{minipage}{0.45\linewidth}
        \centering\normalsize
        Ivan Prosperi
    \end{minipage}
}


\author[Ivan Prosperi]{
    \texorpdfstring{\usebox{\authbox}}{Ivan Prosperi}}
\institute[]{Universit\`a degli Studi di Firenze}
\date{}
\logo{\textcolor{black}{\includegraphics[width=0.10\textwidth]{images/logo_unifi/stemma_grigio.pdf}}}


\AtBeginSection{%
    \begin{frame}
    \tableofcontents[currentsection,subsectionstyle=show/show/hide]
\end{frame}
}

\let\nvec\vec
\def\vec#1{\nvec{\vphantom t\smash{#1}}}
\newcommand{\textplus}{\raisebox{.1\height}{\scalebox{.9}{\texttt{+}}}}

\begin{document}
\definecolor{bg}{rgb}{0.95,0.95,0.95}

\begin{frame}
    \titlepage
    \centering
    Computer Graphics \& 3D Project Report
\end{frame}

\begin{frame}
    \frametitle{Table of contents}
    \tableofcontents[subsubsectionstyle=hide]
\end{frame}

% ##################### START #####################
\section{Introduction}

\subsection{Ambient Occlusion}

\begin{frame}
\frametitle{Ambient Occlusion}
% cosa è, immagini con/senza ao
Ambient occlusion is a shading technique computes the degree of exposure to ambient light in a 3D scene:
\begin{itemize}
    \item open surfaces, planar geometries, ``floating'' geometries: fully exposed to ambient light
    \item corners, hidden geometries, tight gaps between objects, creases: appear shaded in real life, ambient light does not reach them at full intensity
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{Ambient Occlusion Effects}
\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{images/B-25_raw.png}
    \caption{3D object with raw material.\footnotemark}
\end{figure}

\vspace*{-8px}
\footnotetext[1]{\tiny Landis, H. Production-Ready Global Illumination (2004).}
\end{frame}

\begin{frame}
\frametitle{Ambient Occlusion Effects}
\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{images/B-25_ao.png}
    \caption{The same object with ambient occlusion applied.}
\end{figure}

\end{frame}

\subsection{Global Illumination}
\begin{frame}[allowframebreaks]
\frametitle{Global Illumination}
% cosa è, immagini indirect light + AO vera + citazione paper AO
% Dire che ao vera è fatta con indirect lighting di GI ma troppo
% costoso in caso di real time
\textbf{Global Illumination (GI)}:
\begin{itemize}
    \item \emph{considers} physically correct light phenomena
    \item \emph{is} a \underline{global method}: illumination at each point is a function of other geometry in the scene
    \item \emph{accounts} for light rays (possibly infinite) bounces
    \item \emph{implements} indirect illumination
    \item \emph{comprises} reflection, refraction, shadows, diffuse inter-reflections, caustics, etc
\end{itemize}

Ambient occlusion approximates some aspects of Global Illumination.

%\end{frame}
\framebreak
%\begin{frame}
%\frametitle{Global Illumination II}
\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{images/gi_room.jpg}
\end{figure}
%\end{frame}
\framebreak
%\begin{frame}
%\frametitle{Global Illumination III}
Global illumination limits:
\begin{itemize}
    \item a pixel color value depends on the entire scene
    \item light calculation involves solving complex equations
    \item no algorithm exists to implement GI as a whole
\end{itemize}

Furthermore, current real-time graphics hardware is mostly based on rasterization $ \Rightarrow $ ideal for direct illumination computation.

Therefore, \textbf{GI is not reproducible in real time rendering} with the current technologies and hardware.
\end{frame}

\begin{frame}[allowframebreaks]
\frametitle{Multipass Rendering}
% Far vedere esempio di multipass rendering
% Scrivere tipo "used for shadow mapping, normal mapping, etc"
Multipass rendering (and deferred shading) are employed as low-cost approximations for GI effects:
\begin{itemize}
    \item shadow mapping
    \item soft shadows
    \item reflection mapping
    \item light mapping
    \item \textbf{ambient occlusion}
\end{itemize}

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{images/reflection_map.jpg}
\end{figure}

\end{frame}


\section{Screen Space Ambient Occlusion}

\subsection{Principles}

\begin{frame}
\frametitle{Screen Space Ambient Occlusion}
% crytek-crysis 2007
Screen Space Ambient Occlusion (SSAO):
\begin{itemize}
    \item first approach to real time AO
    \item developed at \emph{Crytek GmbH} and included in \emph{CryEngine 2}
    \item used in \emph{Crysis} (2007)
\end{itemize}

\begin{columns}
    \begin{column}{0.4\linewidth}
        \begin{figure}
        \centering
        \subfloat{\includegraphics[width=0.5\linewidth]{images/crytek_logo.pdf}} \\
        \subfloat{\includegraphics[width=0.8\linewidth]{images/cryengine_logo.pdf}}
        \end{figure}
    \end{column}

    \begin{column}{0.4\linewidth}
        \begin{figure}
        \centering
        \includegraphics[width=\linewidth]{images/crysis_cover.png}
        \end{figure}
    \end{column}
\end{columns}

\end{frame}

\begin{frame}
\frametitle{SSAO in Crysis I}
% mettere immagine crysis coreano + tank + muro dietro
\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{images/ssao_crysis_gameplay.png}
\end{figure}
\end{frame}

\begin{frame}
\frametitle{SSAO in Crysis II}
\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{images/ssao_tank.jpg}
\end{figure}

\end{frame}

\begin{frame}
\frametitle{Screen Space}
SSAO is a \emph{screen space} (ss) technique:
\begin{itemize}
    \item uses \emph{deferred rendering} to split geometry render from light computation:
    \begin{itemize}
        \item pass 1: render geometry/depth in off-screen buffers (g-buffer)
        \item pass 2: use g-buffer's rendered scene as texture to apply lighting
    \end{itemize}
    \item ss effects applied in pass 2 $ \Rightarrow $ screen space resolution dependent
    \item application of ss techniques does not depend on scene complexity (roughly)
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Deferred Rendering Pipeline}
\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{images/deferred_rendering.pdf}
\end{figure}

\SetKwFor{ForEach}{for each}{}{}
\begin{columns}
    \begin{column}[t]{0.44\linewidth}
        Forward rendering: $\mathcal{O}(N L R)$
        \smaller
        \begin{algorithm}[H]
            \ForEach{object}{
                \ForEach{fragment}{
                    \ForEach{light}{
                        compute lighting\;
                    }
                }
            }
        \end{algorithm}
    \end{column}
    
    \begin{column}[t]{0.44\linewidth}
        Deferred rendering: $\mathcal{O}((N{+}L)R)$
        \smaller
        \begin{algorithm}[H]
            \ForEach{object}{
                \ForEach{fragment}{
                    fill g-buffer\;
                }
            }
            \ForEach{light}{
                \ForEach{fragment}{
                    fetch g-buffer\;
                    compute lighting\;
                }
            }
        \end{algorithm}
    \end{column}
\end{columns}
\end{frame}

\begin{frame}
\frametitle{SSAO Approach}
SSAO fundamental ideas:
\begin{itemize}
    \item leverage deferred rendering (post processing)
    \item use available geometry info to approximate indirect lighting
    \item use of depth buffer for geometry reconstruction (more on this later)
    \item computation of a screen space occlusion map based on geometries surrounding current rasterized fragment
    \item blending of occlusion map with ambient lighting to shade appropriate portions of the image
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Crytek SSAO}
Crytek's original implementation was never released. High level description available in  \emph{``Finding Next Gen\textemdash{}CryEngine 2''} paper from Crytek.

%Algorithm's high level pseudocode:
%\RestyleAlgo{plain}
\SetKwFor{ForEach}{for each}{}{}
%\SetKwIF\If{cond}{Then’s text}
\SetKwIF{If}{ElseIf}{Else}{if}{}{else if}{else}{endif}
\begin{algorithm}[H]
    render geometry\;
    \ForEach{fragment \textup{in geometry g-buffer}}{
        reconstruct \emph{fragment}'s view space position\;
        sample some points in view space neighborhood\;
        \ForEach{sample}{
            project \emph{sample} in clip space\;
            \If{sample \textup{is behind rasterized geometry}}{
                increment occlusion for current \emph{fragment}\;
            }
        }
        average occlusion for current \emph{fragment} on all \emph{samples}\;
        write $ (1 - \mathit{occlusion}) $ to texture\;
    }
    blend AO map with ambient lighting\;
    \caption{SSAO high level pseudocode.}
\end{algorithm}

\end{frame}

\begin{frame}
\frametitle{SSAO Scheme}
TODO: labels
\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{images/ssao_scheme}
\end{figure}

\end{frame}

\subsection{View Space Reconstruction}
\begin{frame}
\frametitle{Reconstruction From Depth}
Base SSAO: pass a view-space position texture to SSAO shader. Heavy on memory and bandwidth, no processing.

Extension: reconstruct view-space position from depth. No memory footprint (use depth buffer), some processing must be done in shader.
\end{frame}


\newcommand{\transform}[1]{$ \xrightarrow{\text{#1}} $}
\begin{frame}

\frametitle{Background: OpenGL pipeline}
Coordinates: object \transform{MVP} clip \transform{clip/w-divide} NDC \transform{viewport} window.
\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{images/coordinate_systems.png}
\end{figure}

\end{frame}

\begin{frame}
\frametitle{View Space Z from Depth Buffer}
\label{frame:viewspace-from-depth-buffer}

Transformation of z (from view to NDC):
\[
z_{ndc} = \dfrac{z_{clip}}{w_{clip}} = \dfrac{-\dfrac{f+n}{f-n} z_e -2 \dfrac{fn}{f-n}}{-z_e} = \dfrac{\beta z_e + \gamma}{-z_e}
\]

Depth value written in depth buffer:
\[
d = z_{ndc} * 0.5 + 0.5 = \dfrac{(\beta - 1) z_e + \gamma}{-2z_e}
\]

View space position can be reconstructed from depth buffer, given factors $ \beta $ and $ \gamma $ (which depend on $ f $ and $ n $):

\[
z_e = \dfrac{\gamma}{1-2d-\beta}
\]
\end{frame}


\begin{frame}
\frametitle{View Space X and Y}
Transformation of x (from view to NDC):
\[
x_{ndc} = \dfrac{x_{clip}}{w_{clip}} = \dfrac{x_e}{-z_e \alpha \tan(fov/2)}, \quad -1 \le x_{ndc} \le 1
\]

\newlength\halfdiff
\setlength\halfdiff{( \widthof{$ \dfrac{x_e}{-z_e \alpha \tan(fov/2)} $} - \widthof{$\dfrac{x_e}{-z_e}$} ) / 2}
It holds:
\begin{alignat*}{2}
-1 &\le \dfrac{x_e}{-z_e \alpha \tan(fov/2)} &&\le 1 \\
-\alpha \tan(fov/2) &\le \hspace{\halfdiff} \dfrac{x_e}{-z_e} &&\le \alpha \tan(fov/2)
\end{alignat*}

The extremal values represent coordinates for corners of the post-processing full-screen quad. For y coordinates is the same, without $ \alpha $.

Interpolate them to reconstruct the coordinates for all middle pixels.

\end{frame}

\begin{frame}
\frametitle{View Ray}
Solution: 
\begin{itemize}
    \item construct a 2D vector with extremal values multiplied by clip coordinates (called \emph{view ray}):
    \[
    \text{view ray} = \bigl(\alpha \tan(fov/2)\:x_{clip}, \tan(fov/2)\:y_{clip}\bigr)
    \]
    \item Let the hardware interpolate the view ray, then reconstruct position in this way ($ z_e $ is the reconstructed view depth):
    \begin{align*}
    \text{view position} &= z_e \bigl(-\text{view ray}, 1\bigr)\\
                         &= \bigl( x_e, y_e, z_e \bigr)
    \end{align*}
\end{itemize}

\end{frame}

\begin{frame}[fragile]
\frametitle{Vertex Shader}
\begin{minted}[bgcolor=bg,fontsize=\footnotesize]{glsl}
...
void main() {
    vUv = uv;
    vec4 clip = MVP * vec4(position, 1.0);
    view_ray = vec3(-tan(b) * a * clip.x, -tan(b) * clip.y, 1.0);
    gl_Position = clip;
}

\end{minted}
where \mintinline[bgcolor=bg]{glsl}{b} is $ fov/2 $.

Same as before, but prepare 1.0 in last component in advance and pre-multiply -1 in the first two components.
\end{frame}

\begin{frame}[fragile]
\frametitle{Fragment Shader}
\begin{minted}[bgcolor=bg,fontsize=\footnotesize]{glsl}
...
float unproject_depth(const in float depth) {
    return (camera_near * camera_far) /
    ((camera_far - camera_near) * depth - camera_far);
}
void main() {
    ...
    float depth = texture2D(depth_texture, tex_coords).x;
    float view_z = unproject_depth(depth);
    vec3 origin = view_ray * view_z;
    ...
\end{minted}
where \mintinline[bgcolor=bg]{glsl}{origin} is the view space position of the geometry rasterized in the current fragment.

The function \mintinline[bgcolor=bg]{glsl}{unproject_depth} applies the transformation (depth~$ \mapsto $~view space) defined on slide~\ref{frame:viewspace-from-depth-buffer}.

\end{frame}

\subsection{Implementation Details}
% TODO: scrivere che si usa deferred rendering, scrivere tutti i gbuffer che si usano, ..

\begin{frame}[fragile]
\frametitle{Sample kernel}
Uniform variable in fragment shader:
\begin{minted}[bgcolor=bg,fontsize=\footnotesize]{glsl}
uniform vec3 sample_kernel[KERNEL_SIZE];
\end{minted}

It is an array of uniformly \emph{random} vectors s.t. for each vector $ k $ it holds:
\begin{align*}
-1 & \le k.x \le 1 \\
-1 & \le k.y \le 1 \\
0 & \le k.z \le 1
\end{align*}

Forms a hemisphere centered on the origin $ (0, 0, 0) $ $ \Rightarrow $ Use \emph{tangent space}. Must be reoriented inside the shader.
\end{frame}

\begin{frame}[fragile]
\frametitle{Non-Uniformly Distributed Samples}
Samples near the origin are more interesting: use \emph{accelerating interpolation function} to scale the samples:
\begin{minted}[bgcolor=bg,fontsize=\footnotesize]{c++}
float scale = (float)i / KERNEL_SIZE; // i is the loop variable
scale = lerp(0.1f, 1.0f, scale * scale);
sample *= scale;
\end{minted}

\vspace{0.3cm}

\begin{columns}
    \begin{column}{0.45\linewidth}
        \centering
        Uniform samples:
        \begin{figure}
            \centering
            \vspace{-1.8ex}%
            \includegraphics[width=0.7\linewidth]{images/sample_kernel_uniform.pdf}
        \end{figure}
    \end{column}
    
    \begin{column}{0.45\linewidth}
        \centering
        \textbf{Non uniform samples}:
        \begin{figure}
            \centering
            \vspace{-1.8ex}%
            \includegraphics[width=0.7\linewidth]{images/sample_kernel_accel.pdf}
        \end{figure}
        
    \end{column}
\end{columns}

\end{frame}

\begin{frame}[fragile]
\frametitle{Random Kernel Rotations}
To obtain convincing results, a high number of samples must be used $ \Rightarrow $ High memory usage

Solution: use a random $ 4\times4 $ noise texture \emph{tiled} over the screen to rotate the samples.
\begin{minted}[bgcolor=bg, fontsize=\footnotesize]{c++}
noise_texture[i] = Vector3(random(-1,1), random(-1,1), 0);
\end{minted}
\vspace{-1cm}
\begin{minted}[bgcolor=bg, fontsize=\footnotesize]{c++}
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT);
\end{minted} 

Random rotation vectors with z-component equal to 0: in tangent space this describes a rotation around z-axis, that is, around the normal.

\end{frame}

\begin{frame}
\frametitle{Samples Reorientation I}
Samples in tangent space must be transformed to view space and shifted by the current fragment's view position.

\emph{Gram-Schmidt process}: orthonormalization of linearly independent vectors to obtain an orthonormal base.


% TODO: fixme: gram shmidt è quello con cui si costruiscono tangente e bitangente da normale e noise. Poi si trasforma con TBN per riorentare sample kernel.

Transformation matrix:
\[
\text{TBN} = 
\begin{bmatrix}
\vec{t} & \vec{b} & \vec{n}
\end{bmatrix} \in \mathbb{R}^{3\times3}
\]
where $ \vec{t} $ is the tangent, $ \vec{b} $ is the bitangent and $ \vec{n} $ is the normal.

Matrix application:
\[ \vec{v}_{\text{view-space}} = \text{TBN} \; \vec{v}_{\text{tangent-space}} \]
\end{frame}

\begin{frame}[fragile]
\frametitle{Sample Reorientation II}

TBN creation in fragment shader:
\begin{minted}[bgcolor=bg, fontsize=\footnotesize]{glsl}
vec3 tangent = normalize(noise - normal * dot(noise, normal));
vec3 bitangent = cross(normal, tangent);
mat3 tbn = mat3(tangent, bitangent, normal);
\end{minted}

\begin{figure}
    \includegraphics[width=0.7\linewidth]{images/kernel_reorientation.pdf}
    \centering
\end{figure}

\end{frame}

\begin{frame}[fragile]
\frametitle{Sample Reorientation III}
SSAO shader main loop.

To get a sample's view position:
\begin{itemize}
    \item reorient sample
    \item adjust radius
    \item add origin point (fragment's view space)
\end{itemize}
\begin{minted}[bgcolor=bg, fontsize=\footnotesize]{glsl}
float occlusion = 0.0;
for (int i = 0; i < KERNEL_SIZE; ++i) {
    vec3 sample_point = tbn * sample_kernel[i];
    sample_point = (sample_point * kernel_radius) + origin;
    ...
\end{minted}

\end{frame}

\begin{frame}[fragile]
\frametitle{Projection}
The overall process comprises:
\begin{itemize}
    \item use projection matrix to project in clip space
    \item perform perspective divide
    \item bias, to get coordinates in $ [0,1] $
\end{itemize}

\begin{minted}[bgcolor=bg, fontsize=\footnotesize]{glsl}
    vec4 sample_point_ndc = projection_matrix * vec4(sample_point, 1.0);
    sample_point_ndc.xy /= sample_point_ndc.w;
    vec2 sample_point_uv = sample_point_ndc.xy * 0.5 + 0.5;
    ...
\end{minted}

The variable \verb|sample_point_uv| represents the texture coordinates of the projected sample.

\end{frame}

\begin{frame}[fragile]
\frametitle{Depth Comparison}
Compare the depth value in depth buffer (true rasterized geometry) with the depth value of the sample.

Use the above defined \verb|sample_point_uv| as texture coordinates.

\begin{minted}[bgcolor=bg, fontsize=\footnotesize]{glsl}
    float real_depth = texture2D(t_depth, sample_point_uv).r;
    float linear_real_depth = unproject_depth(real_depth);
    float sample_depth = sample_point.z;
    
    float delta = linear_real_depth - sample_depth;
    ...
\end{minted}

Discriminate on \verb|delta| value whether this sample contributes to occlusion or not.
\end{frame}

\begin{frame}[fragile]
\frametitle{Occlusion Computation: Naive Approach}
Naive approach:
\begin{minted}[bgcolor=bg, fontsize=\footnotesize]{glsl}
    if (delta >= 0.0) {
        occlusion += 1.0;
    }
    ...
\end{minted}

\begin{columns}
    \begin{column}{0.45\linewidth}
        Binary valued occlusion:
        \begin{itemize}
            \item too coarse, might generate artifacts
            \item overshadows overlapping geometries, even if distant
        \end{itemize}
    \end{column}
    \begin{column}{0.45\linewidth}
        \begin{figure}
            \centering
            \includegraphics[width=0.8\linewidth]{images/occlusion_naive}
        \end{figure}
    \end{column}
\end{columns}

\end{frame}

\begin{frame}[fragile]
\frametitle{Occlusion Computation: Range Check}
Range check inclusion:
\begin{minted}[bgcolor=bg, fontsize=\footnotesize]{glsl}
    float range_check = abs(linear_real_depth - origin.z)
        < kernel_radius ? 1.0 : 0.0;
    occlusion += (delta >= 0.0 ? 1.0 : 0.0) * range_check;
    ...
\end{minted}

\begin{columns}
    \begin{column}{0.45\linewidth}
        Binary valued occlusion with range check:
        \begin{itemize}
            \item still coarse. Visible artifacts (see next slide)
            \item overshadowing of distant geometries solved
        \end{itemize}
    \end{column}
    \begin{column}{0.45\linewidth}
        \begin{figure}
            \centering
            \includegraphics[width=0.8\linewidth]{images/occlusion_hard_range_check.png}
        \end{figure}
    \end{column}
\end{columns}

\end{frame}

\begin{frame}[fragile]
\frametitle{Occlusion Computation: Range Check (soft)}
Soft range check inclusion:
\begin{minted}[bgcolor=bg, fontsize=\footnotesize]{glsl}
    float value = kernel_radius / abs(linear_real_depth - origin.z);
    float range_check = smoothstep(0.0, 1.0, value);
    occlusion += (delta >= 0.0 ? 1.0 : 0.0) * range_check;
    ...
\end{minted}

\begin{columns}
    \begin{column}{0.45\linewidth}
        Continuous valued occlusion with range check:
        \begin{itemize}
            \item finer control over AO; artifacts removed/attenuated
            \item overshadowing of distant geometries solved
        \end{itemize}
    \end{column}
    \begin{column}{0.45\linewidth}
        \begin{figure}
            \centering
            \includegraphics[width=0.8\linewidth]{images/occlusion_soft_range_check.png}
        \end{figure}
    \end{column}
\end{columns}

\end{frame}

\begin{frame}[fragile]
\frametitle{Occlusion Computation: Range Check (soft) II}
Soft range check inclusion: resolves artifacts.
\begin{minted}[bgcolor=bg, fontsize=\footnotesize]{glsl}
    float value = kernel_radius / abs(linear_real_depth - origin.z);
    float range_check = smoothstep(0.0, 1.0, value);
    occlusion += (delta >= 0.0 ? 1.0 : 0.0) * range_check;
    ...
\end{minted}

\begin{columns}
    \begin{column}{0.45\linewidth}
    \centering
        Hard range check:
        \begin{figure}
            \centering
            \vspace{-1.8ex}%
            \includegraphics[width=0.8\linewidth]{images/feet_hard_range_check.png}
        \end{figure}
    \end{column}

    \begin{column}{0.45\linewidth}
        \centering
        Soft range check
        \begin{figure}
            \centering
            \vspace{-1.8ex}%
            \includegraphics[width=0.8\linewidth]{images/feet_soft_range_check.png}
        \end{figure}
    \end{column}
\end{columns}

\end{frame}

\begin{frame}[fragile]
\frametitle{Distance Constraints}
Add constraints to avoid artifacts at corners:
\begin{itemize}
    \item constraints applied on depth distance from actual geometry to sample
    \item ability to tune the effect according to the scene
\end{itemize}


\begin{minted}[bgcolor=bg, fontsize=\footnotesize]{glsl}
    float value = kernel_radius / abs(linear_real_depth - origin.z);
    float range_check = smoothstep(0.0, 1.0, value);
    float constraints = (delta >= min_distance && delta < max_distance);
    occlusion += (constraints ? 1.0 : 0.0) * range_check;
    ...
\end{minted}
\end{frame}

\begin{frame}
\frametitle{Blur}
A blur pass is necessary to filter high frequency pattern introduced by noise texture.

Implemented in a second shader, applied after SSAO shader.

\vspace{0.6cm}

\begin{columns}
    \begin{column}{0.45\linewidth}
        \centering
        SSAO
        \begin{figure}
            \vspace{-1.8ex}%
            \includegraphics[width=0.7\linewidth]{images/no_blur.png}
        \end{figure}
    \end{column}
    
    \begin{column}{0.45\linewidth}
        \centering
        SSAO + Blur
        \begin{figure}
            \vspace{-1.8ex}%
            \includegraphics[width=0.7\linewidth]{images/blur.png}
        \end{figure}
    \end{column}
\end{columns}

\end{frame}


\section{Results}

\begin{frame}
\frametitle{Application}
A web application was created to show the results of the project.

Scene created with publicly available 3D models.
\vspace{0.6cm}
\begin{columns}
    \begin{column}[t]{0.45\linewidth}
        Four views available:
        \begin{itemize}
            \item complete
            \item beauty
            \item SSAO
            \item SSAO + blur
        \end{itemize}
    \end{column}

    \begin{column}[t]{0.45\linewidth}
        Configurable parameters:
        \begin{itemize}
            \item kernel radius
            \item minimum / maximum distances
            \item range check factor
            \item power factor
        \end{itemize}
    \end{column}

\end{columns}

\end{frame}

\newcommand{\resultwidth}{0.9\linewidth}

\begin{frame}
\frametitle{App: SSAO Layer}
\begin{figure}
    \centering
    \includegraphics[width=\resultwidth]{images/app_ssao}
\end{figure}

\end{frame}

\begin{frame}
\frametitle{App: Blur Layer}
\begin{figure}
    \centering
    \includegraphics[width=\resultwidth]{images/app_blur}
\end{figure}

\end{frame}

\begin{frame}
\frametitle{App: Beauty Layer}
\begin{figure}
    \centering
    \includegraphics[width=\resultwidth]{images/app_beauty}
\end{figure}

\end{frame}

\begin{frame}
\frametitle{App: Complete Layer}
\begin{figure}
    \centering
    \includegraphics[width=\resultwidth]{images/app_complete}
\end{figure}

\end{frame}

\section{Tools and Software}
\begin{frame}
\frametitle{Tools and Software}
% threejs webgl buildpack node/npm heroku eslint
The project was realized in Javascript, using the 3D graphics library three.js (WebGL).

Node.js and its package manager npm were used to provide dependency management and deployment.

The Webpack bundler was used to assemble the project. Hosted on Heroku.
\begin{figure}
    \centering
    \includegraphics[width=0.6\linewidth]{images/software_logos.pdf}
\end{figure}


\end{frame}

\section{Conclusions}

\begin{frame}
\frametitle{Known Problems}
The encountered problems are those typical of SSAO technique:
\begin{itemize}
    \item halo effect on object borders (bleeding): due to ``blind'' blur
    \item high number of parameters, hard to find a global optimum
    \item SSAO effects greatly depends on scene scale and complexity
\end{itemize}

Possible solution for SSAO bleeding: depth aware blur.

More recently, some advanced algorithms have been developed: HBAO/HBAO\textplus, SSDO, RTAO, etc.
\end{frame}



\begin{frame}
\frametitle{Conclusions}
Features of this project:
\begin{itemize}
    \item fully functioning project realized with latest technologies
    \item deployed on a public hosting service
    \item showcases the Screen Space Ambient Occlusion technique
    \item includes fixes and improvements over the original method
    \item adopts a depth reconstruction methodology
\end{itemize}

Links to the project repository and online version:
\begin{itemize}
    \item \url{https://github.com/ivan94fi/cg3d_project_ssao}
    \item \url{https://cg3d-project-ssao.herokuapp.com/}
\end{itemize}

\end{frame}

% ##################### END #####################

\end{document}